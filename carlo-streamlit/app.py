# app.py

import streamlit as st
from datetime import datetime
import threading
import time
import pandas as pd
import requests
from bs4 import BeautifulSoup
import os
from cryptography.fernet import Fernet

# -------------------------------
# 1Ô∏è‚É£ Barre sup√©rieure avec ton nom et horloge dynamique
# -------------------------------

# Cr√©er un placeholder pour afficher l'horloge
clock_placeholder = st.empty()

# Fonction qui met √† jour l'horloge toutes les secondes
def update_clock():
    while True:
        now = datetime.now().strftime("%H:%M:%S")  # Format HH:MM:SS
        clock_placeholder.markdown(
            f"<h3 style='color:white;'>{now}</h3>", unsafe_allow_html=True
        )
        time.sleep(1)  # Met √† jour toutes les secondes

# Barre sup√©rieure HTML/CSS
st.markdown(
    """
    <div style="display:flex; justify-content:space-between; align-items:center; 
                background-color:#4CAF50; padding:10px; border-radius:5px;">
        <h2 style="color:white;">Guillaume Saucy - Dashboard Webscraping</h2>
        <div id='clock'></div>
    </div>
    """,
    unsafe_allow_html=True
)

# Lancer l‚Äôhorloge dans un thread s√©par√©
thread = threading.Thread(target=update_clock, daemon=True)
thread.start()

st.write("## Bienvenue sur le dashboard !")

# -------------------------------
# 2Ô∏è‚É£ Section de connexion Carlo Erba
# -------------------------------

st.write("### Connexion Carlo Erba")

# Entr√©e email et mot de passe
email = st.text_input("Email")
password = st.text_input("Mot de passe", type="password")

# Case √† cocher pour se souvenir des identifiants
remember = st.checkbox("Se souvenir de moi")

# -------------------------------
# 3Ô∏è‚É£ S√©lection des r√©f√©rences √† scraper
# -------------------------------

st.write("### S√©lection des r√©f√©rences")

# Option Excel, manuel ou les deux
search_option = st.radio(
    "Mode de recherche",
    ('Excel', 'Manuel', 'Excel + Manuel')
)

# S√©lection fichier Excel si option choisie
excel_path = None
if search_option in ['Excel', 'Excel + Manuel']:
    excel_path = st.file_uploader("Choisir un fichier Excel", type=['xlsx', 'xls'])

# Entr√©e manuelle de r√©f√©rences
manual_references = st.text_input("R√©f√©rences manuelles (s√©par√©es par une virgule)")

# -------------------------------
# 4Ô∏è‚É£ Fonction de scraping Carlo Erba
# -------------------------------

def carloerba_scraper(email, password, excel_path, manual_references, search_option):
    """Fonction principale de scraping Carlo Erba"""
    if not email or not password:
        st.warning("‚ö†Ô∏è Veuillez entrer vos identifiants.")
        return None

    # Cr√©er session persistante
    session = requests.Session()

    # √âtape 1 : R√©cup√©rer CSRF token
    login_page_url = "https://www.carloerbareagents.com/cerstorefront/cer-fr/login"
    resp = session.get(login_page_url)
    soup = BeautifulSoup(resp.text, "lxml")
    csrf_token = soup.find("input", {"name": "CSRFToken"})["value"]

    st.info(f"üîë CSRFToken r√©cup√©r√© : {csrf_token}")

    # √âtape 2 : Connexion
    payload = {
        "j_username": email,
        "j_password": password,
        "CSRFToken": csrf_token
    }

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": login_page_url,
        "Origin": "https://www.carloerbareagents.com",
        "Content-Type": "application/x-www-form-urlencoded",
    }

    login_url = "https://www.carloerbareagents.com/cerstorefront/cer-fr/j_spring_security_check"
    response = session.post(login_url, data=payload, headers=headers, allow_redirects=False)

    if response.status_code != 302:
        st.error("‚ùå Connexion √©chou√©e.")
        return None
    st.success("‚úÖ Connexion r√©ussie.")

    # -------------------------------
    # 3Ô∏è‚É£ R√©cup√©rer les r√©f√©rences selon l‚Äôoption choisie
    # -------------------------------

    references = []

    if search_option in ['Excel', 'Excel + Manuel'] and excel_path is not None:
        df_refs = pd.read_excel(excel_path)
        references.extend(df_refs['R√©f√©rence'].dropna().astype(str).tolist())

    if search_option in ['Manuel', 'Excel + Manuel'] and manual_references:
        references.extend([ref.strip() for ref in manual_references.split(',')])

    if not references:
        st.warning("‚ö†Ô∏è Aucune r√©f√©rence √† rechercher.")
        return None

    # -------------------------------
    # 4Ô∏è‚É£ Scraping des produits
    # -------------------------------

    data = []
    progress_bar = st.progress(0)
    status_text = st.empty()

    total = len(references)
    for idx, ref in enumerate(references):
        status_text.text(f"üîç Recherche de la r√©f√©rence : {ref} ({idx+1}/{total})")
        search_url = f"https://www.carloerbareagents.com/cerstorefront/cer-fr/search/?text={ref}"
        resp = session.get(search_url)

        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            products = soup.find_all('tr', class_='quickAddToCart')

            if not products:
                st.warning(f"‚ùå Aucun produit trouv√© pour : {ref}")
                continue

            for product in products:
                try:
                    product_name = product.find('input', {'name': 'productNamePost'}).get('value')
                    conditionnement = product.find('td', class_='item__info--variantDescription').text.strip()
                    tds = product.find_all('td')
                    emballage = tds[2].text.strip() if len(tds) > 2 else ""
                    unite_vente = tds[3].text.strip() if len(tds) > 3 else ""
                    quantite_input = product.find('input', {'name': 'initialQuantityVariant'})
                    quantite = quantite_input.get('value') if quantite_input else ""
                    price = product.find('input', {'name': 'productPostPrice'}).get('value')
                    availability_icon = product.find('i')
                    availability_title = availability_icon.get('title') if availability_icon else None

                    if availability_title == "Produit en stock":
                        disponibilite = "En stock"
                    elif availability_title == "Disponible sous 15 jours":
                        disponibilite = "Disponible sous 15 jours"
                    elif availability_title == "Disponible en plus de 30 jours":
                        disponibilite = "Disponible en plus de 30 jours"
                    else:
                        disponibilite = "Non pr√©cis√©"

                    # Ajouter les donn√©es
                    data.append({
                        'R√©f√©rence cherch√©e': ref,
                        'Produit': product_name,
                        'Cdt': conditionnement,
                        'Emballage': emballage,
                        'Unit√© de vente': unite_vente,
                        'Qt√©': quantite,
                        'Prix ‚Ç¨': price,
                        'Disponibilit√©': disponibilite
                    })

                except Exception as e:
                    st.error(f"‚ö†Ô∏è Erreur pour {ref} : {e}")
                    continue

        else:
            st.error(f"‚ùó Erreur HTTP pour : {ref} (code {resp.status_code})")

        # Mise √† jour barre de progression
        progress_bar.progress((idx + 1) / total)

    # -------------------------------
    # 5Ô∏è‚É£ Affichage des r√©sultats
    # -------------------------------

    if data:
        df_resultats = pd.DataFrame(data)
        st.success("‚úÖ Scraping termin√© !")
        # Affichage avec couleurs selon disponibilit√©
        def color_availability(val):
            if val == "En stock":
                return 'background-color: lightgreen'
            elif val.startswith("Disponible"):
                return 'background-color: lightyellow'
            else:
                return 'background-color: lightcoral'

        st.dataframe(df_resultats.style.applymap(color_availability, subset=['Disponibilit√©']))

        # Export Excel automatique
        output_file = "resultats_scraping.xlsx"
        df_resultats.to_excel(output_file, index=False)
        st.info(f"Donn√©es enregistr√©es dans : {output_file}")
    else:
        st.warning("‚ö†Ô∏è Aucun produit trouv√©.")

# -------------------------------
# 5Ô∏è‚É£ Bouton de lancement
# -------------------------------
if st.button("Lancer le scraping"):
    carloerba_scraper(email, password, excel_path, manual_references, search_option)
